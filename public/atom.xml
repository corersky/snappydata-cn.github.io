<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SnappyData中文博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-05-17T08:31:57.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>经营效率小队</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>客户端连接SnappyData</title>
    <link href="http://yoursite.com/2018/05/17/%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5SnappyData/"/>
    <id>http://yoursite.com/2018/05/17/客户端连接SnappyData/</id>
    <published>2018-05-17T02:33:46.000Z</published>
    <updated>2018-05-17T08:31:57.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Snappy-SQL交互命令行"><a href="#Snappy-SQL交互命令行" class="headerlink" title="Snappy-SQL交互命令行"></a>Snappy-SQL交互命令行</h3><p>通过Apache Derby ij tool，SnappyData实现了一个交互式的命令行工具: <strong>snappy</strong>。通过此脚本便可在SnappyData集群中运行SQL命令或SQL脚本，此文件位于bin目录下。</p><p>在创建JDBC连接前，你可以通过<strong>snappy.history</strong>指定一个路径，来保留未来执行的所有SQL命令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ export JAVA_ARGS=&quot;-Dsnappy.history=/temp/snappydata-history.sql&quot;</span><br><span class="line">$ ./snappy</span><br></pre></td></tr></table></figure><a id="more"></a><p>注意：这里选择snappy脚本和snappy-sql脚本都可以，snappy-sql最终也是要调用snappy脚本执行。</p><p>接下来就可以创建连接并执行SQL命令，需要注意的是所有命令都以分号结尾，并且不区分大小写。</p><p>通常我们指定一个locator hostname进行连接，默认端口1527.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ./bin/snappy</span><br><span class="line">snappy&gt; connect client &apos;&lt;locatorHostName&gt;:1527&apos;;</span><br></pre></td></tr></table></figure><p>指定locator后，locator会将连接请求根据负载情况发送到某个server节点并返回客户端已经连接的消息，客户端执行的所有sql命令都由这个server进行解析。</p><p><img src="/2018/05/17/客户端连接SnappyData/p1.png" alt=""></p><p>当然也可以执行show、describe等命令来查看其他信息，具体命令可通过<strong>help</strong>来查看帮助。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">elapsedtime on;</span><br><span class="line">show connections;</span><br><span class="line">show members;</span><br><span class="line">describe &lt;Table_Name&gt;;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="JDBC连接"><a href="#JDBC连接" class="headerlink" title="JDBC连接"></a>JDBC连接</h3><p>JDBC连接到SnappyData 1.0.0(1.0.1)，需要引入如下依赖：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- https://mvnrepository.com/artifact/io.snappydata/snappydata-store-client --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;io.snappydata&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;snappydata-store-client&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.6.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt;     </span><br><span class="line">  &lt;artifactId&gt;libthrift&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;0.9.2&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;spark-unsafe_2.11&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;2.0.2&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>Driver要选择<strong>io.snappydata.jdbc.ClientDriver</strong>，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Class.forName(&quot;io.snappydata.jdbc.ClientDriver&quot;);</span><br><span class="line">// Locator或Server默认的监听端口号为1527</span><br><span class="line">Connection c = DriverManager.getConnection (&quot;jdbc:snappydata://locatorHostName:1527/&quot;);</span><br></pre></td></tr></table></figure><h3 id="第三方客户端工具"><a href="#第三方客户端工具" class="headerlink" title="第三方客户端工具"></a>第三方客户端工具</h3><p>为了便于开发测试，用户也可以选择一个第三方工具进行JDBC连接。一般情况下所有工具都没有自带SnappyData的Driver，所以用户需要手动将所需的依赖拷贝到lib目录或者通过配置添加，并指定Driver class为<strong>io.snappydata.jdbc.ClientDriver</strong>。</p><p>这里我们以“<strong><a href="http://squirrel-sql.sourceforge.net/" target="_blank" rel="noopener">SQuirrel SQL</a></strong>”的客户端工具为例，来说明配置的步骤。</p><h4 id="需要的依赖"><a href="#需要的依赖" class="headerlink" title="需要的依赖"></a>需要的依赖</h4><p>依赖列表如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">snappydata-store-client-1.6.0.jar</span><br><span class="line">snappydata-store-shared-1.6.0.jar</span><br><span class="line">gemfire-shared-1.6.0.jar</span><br><span class="line">commons-io-2.5.jar</span><br><span class="line">gemfire-trove-1.6.0.jar</span><br><span class="line">slf4j-log4j12-1.7.21.jar</span><br><span class="line">slf4j-api.1.7.21.jar</span><br><span class="line">libthrift-0.9.2.jar</span><br><span class="line">spark-unsafe_2.11-2.0.2.jar</span><br><span class="line">spark-tags_2.11-2.0.2.jar</span><br></pre></td></tr></table></figure><p>其中1-7都封装在snappydata-store-client中，8则属于libthrift，9-10封装在spark-unsafe_2.11中。</p><h4 id="界面配置"><a href="#界面配置" class="headerlink" title="界面配置"></a>界面配置</h4><p>在<strong>Drivers</strong>界面，添加一个新的Driver，并将需要的依赖分别添加，<strong>Class Name</strong>项选择“io.snappydata.jdbc.ClientDriver”。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Driver Name: Apache SnappyData</span><br><span class="line">Example URL: jdbc:snappydata://&lt;locatorHostName&gt;:&lt;locatorClientPort&gt;/</span><br><span class="line">Website URL: https://snappydatainc.github.io/snappydata/howto/connect_using_jdbc_driver/</span><br><span class="line"></span><br><span class="line">Class Name: io.snappydata.jdbc.ClientDriver</span><br></pre></td></tr></table></figure><p>截图如下：</p><p><img src="/2018/05/17/客户端连接SnappyData/p2.png" alt=""></p><p>Driver配置完成后，开始配置URL连接，在<strong>Aliases</strong>界面，添加一个SnappyData Driver的URL连接。</p><p><img src="/2018/05/17/客户端连接SnappyData/p3.png" alt=""></p><p>连接成功后，执行查询：</p><p><img src="/2018/05/17/客户端连接SnappyData/p4.png" alt=""></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从使用角度来说，SnappyData完全可以当作MySQL使用，SQL语法是标准SQL+Spark SQL，支持分析函数，比MySQL功能还要强大。</p><p>从性能角度看，SnappyData的OLAP功能和MySQL没有可比性，OLAP功能强大。</p><p>从灵活度角度看，SnappyData支持自由的探索，AdHoc查询用起来非常灵活、快速、实时，这点是Kylin和Druid等预聚合系统无法达到的。</p><p>从易用性角度看，支持SQL，这对于分析人员来讲门槛降低，效率大大提升。</p><p>从业务角度看，支持update、delete、支持join，业务分析更灵活。</p><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p><a href="https://snappydatainc.github.io/snappydata/reference/interactive_commands/store_command_reference/" target="_blank" rel="noopener">Snappy-SQL Shell Interactive Commands</a></p><p><a href="https://snappydatainc.github.io/snappydata/howto/use_snappy_shell/" target="_blank" rel="noopener">How to Use Snappy SQL shell (snappy-sql)</a></p><p><a href="https://snappydatainc.github.io/snappydata/howto/connect_using_jdbc_driver/" target="_blank" rel="noopener">How to Connect using JDBC Driver</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Snappy-SQL交互命令行&quot;&gt;&lt;a href=&quot;#Snappy-SQL交互命令行&quot; class=&quot;headerlink&quot; title=&quot;Snappy-SQL交互命令行&quot;&gt;&lt;/a&gt;Snappy-SQL交互命令行&lt;/h3&gt;&lt;p&gt;通过Apache Derby ij tool，SnappyData实现了一个交互式的命令行工具: &lt;strong&gt;snappy&lt;/strong&gt;。通过此脚本便可在SnappyData集群中运行SQL命令或SQL脚本，此文件位于bin目录下。&lt;/p&gt;
&lt;p&gt;在创建JDBC连接前，你可以通过&lt;strong&gt;snappy.history&lt;/strong&gt;指定一个路径，来保留未来执行的所有SQL命令:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ export JAVA_ARGS=&amp;quot;-Dsnappy.history=/temp/snappydata-history.sql&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ ./snappy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="业务应用" scheme="http://yoursite.com/categories/%E4%B8%9A%E5%8A%A1%E5%BA%94%E7%94%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>SnappyData在生产中的应用-1</title>
    <link href="http://yoursite.com/2018/04/28/SnappyData%E5%9C%A8%E7%94%9F%E4%BA%A7%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8-1/"/>
    <id>http://yoursite.com/2018/04/28/SnappyData在生产中的应用-1/</id>
    <published>2018-04-28T03:22:21.000Z</published>
    <updated>2018-04-28T08:50:04.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、建表原则"><a href="#一、建表原则" class="headerlink" title="一、建表原则"></a>一、建表原则</h2><p>SnappyData中的表可以简单分为维度表与事实表两类，除此之外还有流表、采样表与临时表等，这里只讨论维度表与事实表，用于<strong>实时的、自由的、极速的、探索性</strong>的OLAP分析(Realtime-OLAP)。</p><p>通常建议将数据量较少的(万级别以下)维度表设置为replicated的行表，这样维度表会在每个节点中分别存一份。但是如果遇到维度表比较大且也会发生变化时(十万、百万级别以上)，建议将表创建为列表，hash分区键指定为与事实表相同的列，例如goods_id列，此时的维度表就变为了事实表。</p><p>事实表的数据量通常较大，一般设置为列表，hash分区键指定为与维度表相同的列，且明确指出与维度表进行colocate存储。目前列表上暂不支持对分区键的二级list分区或range分区。</p><a id="more"></a><h2 id="二、建表DDL语句"><a href="#二、建表DDL语句" class="headerlink" title="二、建表DDL语句"></a>二、建表DDL语句</h2><h3 id="1、维度表转事实表goods表"><a href="#1、维度表转事实表goods表" class="headerlink" title="1、维度表转事实表goods表"></a>1、维度表转事实表goods表</h3><p>由于维度表数据量接近300万，且字段较多，因此占用的内存空间较大，并不适合设计成每个节点都存储一份的维度表，所以将原维度表设计为一张事实表，按照goods_id进行hash分区：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/goods.png" alt=""></p><h3 id="2、事实表order表"><a href="#2、事实表order表" class="headerlink" title="2、事实表order表"></a>2、事实表order表</h3><p>事实表的数据量较大，这里以订单表为例，同样按照goods_id进行hash分区，但要指定和goods表进行colocate存储：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/order.png" alt=""></p><h3 id="3、维度表brand表"><a href="#3、维度表brand表" class="headerlink" title="3、维度表brand表"></a>3、维度表brand表</h3><p>可以将只有几千条的brand表设计为replicated的行表，这样brand表就会在每个节点都存储一份：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/brand.png" alt=""></p><h2 id="三、数据实时导入"><a href="#三、数据实时导入" class="headerlink" title="三、数据实时导入"></a>三、数据实时导入</h2><p>SnappyData支持流表，允许接入kafka进行实时导入。但是对kafka的版本有要求。</p><p>我们的业务需要对表中的数据进行update更新操作，因此通过flink进行实时ETL或窗口类处理后，导入到SnappyData的维度表与事实表。</p><p>当进行纯粹的insert操作时，延迟在毫秒级；当需要进行update操作时，由于数据量较大，为避免lead的压力过大、避免server处理频繁的update操作，因此在flink中实现SQL的<strong>批量更新</strong>，延迟在1分钟，但更新效率极高，这也是在低延迟和高吞吐之间进行了一次取舍。</p><h2 id="四、查询类型"><a href="#四、查询类型" class="headerlink" title="四、查询类型"></a>四、查询类型</h2><p>可以将查询分为3类：单表查询；维度表与事实表join；事实表与事实表join。</p><h3 id="1、单表查询"><a href="#1、单表查询" class="headerlink" title="1、单表查询"></a>1、单表查询</h3><p>进行单表查询时，可以对表中任何一个字段进行任何类型的SQL操作，例如投影、选择、链接等，即可以对数据进行自由、极速的探索性ad-hoc类查询。</p><p>我们以订单表为例，查看过去7天的订单状态分布情况：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/sql.png" alt=""></p><p>可以看到，在一个上亿记录的表上进行任意字段的聚合操作，延迟在毫秒级。</p><h3 id="2、事实表与维度表join查询-流批join"><a href="#2、事实表与维度表join查询-流批join" class="headerlink" title="2、事实表与维度表join查询(流批join)"></a>2、事实表与维度表join查询(流批join)</h3><p>我们将goods表和brand表进行join，goods表是随着时间实时变化的，因此可以看作事实表，而brand基本不变，且是replicated的行表，因此看作维度表：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/batch_stream_join.png" alt=""></p><p>可以看到，查询在毫秒级完成。</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/batch_stream_join_plan.png" alt=""></p><p>再看其执行计划，可以看到SnappyHashJoin,即两个表的join时，先在节点本地进行join，这样的效率比跨节点广播效率高的多。</p><h3 id="3、事实表与事实表join查询-双流join"><a href="#3、事实表与事实表join查询-双流join" class="headerlink" title="3、事实表与事实表join查询(双流join)"></a>3、事实表与事实表join查询(双流join)</h3><p>这里我们举3个例子，其中既包含了涉及子查询，也包含了双流join与维度表join，也包括了自定义UDF。</p><p>先看下整体的查询耗时情况：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/生产--耗时1.png" alt=""></p><p>生产上的查询基本不到1s中就可以查询到，数据量从几亿到几十亿的join。</p><p>再看下具体的SQL执行情况。</p><h4 id="3-1、双流join-维度表join"><a href="#3-1、双流join-维度表join" class="headerlink" title="3.1、双流join+维度表join"></a>3.1、双流join+维度表join</h4><p>我们先看下2个事实表与1个维度表的join情况：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/实时1.png" alt=""></p><p>耗时在1秒内，数据量为1.5亿，聚合字段为非分区键。</p><h4 id="3-2、子查询多表join"><a href="#3-2、子查询多表join" class="headerlink" title="3.2、子查询多表join"></a>3.2、子查询多表join</h4><p>另一个例子是涉及到了子查询，且SQL中包含了各种内置函数以及窗口函数：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/实时2.png" alt=""></p><p>在10亿条数据的表上进行复杂的SQL查询，耗时0.4s。</p><p>其部分查询计划如下：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/实时4.png" alt=""></p><p>由于存在子集合，因此子集合数据会广播出去，效率没有本地join高。但由于广播的数据较小，因此查询效率并未受到太多影响。在设计查询SQL时，应尽量避免子集合，实在没办法避免时，应选择将较小的表作为子集合广播。</p><h4 id="3-3、UDF后的join"><a href="#3-3、UDF后的join" class="headerlink" title="3.3、UDF后的join"></a>3.3、UDF后的join</h4><p>由于涉及到排序以及复杂的运算，因此为了更高效的执行SQL，因此实现了自定义UDF函数。</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/实时6.png" alt=""></p><p>数据量在40亿，与其他事实表join的耗时在0.2s。</p><p>其执行计划完全是SnappyHashJoin，即本地操作且没有sort类操作：</p><p><img src="/2018/04/28/SnappyData在生产中的应用-1/实时7.png" alt=""></p><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>这篇文章中涉及了如何创建表，以及几个需要注意的点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、列表默认的partition数量为128，因此为了最大化的并行执行，需要根据集群规模设定每个表的partition数</span><br><span class="line">2、hash分区键的选择，应该尽量选择最常用的join列，且基数较大的列(至少超过partition数)</span><br><span class="line">3、尽可能的使得join本地执行</span><br><span class="line">4、业务复杂且涉及排序，尽可能自定义UDF提高效率</span><br></pre></td></tr></table></figure><p>之后的文章，我们会介绍如何利用监控界面在SnappyData中使用SQL进行优化，同时会涉及SQL优化的指导原则。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、建表原则&quot;&gt;&lt;a href=&quot;#一、建表原则&quot; class=&quot;headerlink&quot; title=&quot;一、建表原则&quot;&gt;&lt;/a&gt;一、建表原则&lt;/h2&gt;&lt;p&gt;SnappyData中的表可以简单分为维度表与事实表两类，除此之外还有流表、采样表与临时表等，这里只讨论维度表与事实表，用于&lt;strong&gt;实时的、自由的、极速的、探索性&lt;/strong&gt;的OLAP分析(Realtime-OLAP)。&lt;/p&gt;
&lt;p&gt;通常建议将数据量较少的(万级别以下)维度表设置为replicated的行表，这样维度表会在每个节点中分别存一份。但是如果遇到维度表比较大且也会发生变化时(十万、百万级别以上)，建议将表创建为列表，hash分区键指定为与事实表相同的列，例如goods_id列，此时的维度表就变为了事实表。&lt;/p&gt;
&lt;p&gt;事实表的数据量通常较大，一般设置为列表，hash分区键指定为与维度表相同的列，且明确指出与维度表进行colocate存储。目前列表上暂不支持对分区键的二级list分区或range分区。&lt;/p&gt;
    
    </summary>
    
      <category term="业务应用" scheme="http://yoursite.com/categories/%E4%B8%9A%E5%8A%A1%E5%BA%94%E7%94%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>Google Shasta解读</title>
    <link href="http://yoursite.com/2018/04/09/Google-Shasta%E8%A7%A3%E8%AF%BB/"/>
    <id>http://yoursite.com/2018/04/09/Google-Shasta解读/</id>
    <published>2018-04-09T09:13:58.000Z</published>
    <updated>2018-04-10T08:18:55.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Shasta系统架构"><a href="#Shasta系统架构" class="headerlink" title="Shasta系统架构"></a>Shasta系统架构</h2><p>Google内部广告业务的数据分析，需要满足3方面的需求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1、查询的延迟要低</span><br><span class="line">2、查询的表达要简单</span><br><span class="line">3、查询的结果要及时更新</span><br></pre></td></tr></table></figure><a id="more"></a><p>为了支持这3方面的需求，Google内部开发了一个叫做Shasta的广告分析引擎，允许用户以较低的延迟、简单的类SQL语句查询复杂的、实时更新的数据。</p><p>具体的需求如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1、数据存储多样化(F1、Mesa，Shasta本身并不是存储引擎)</span><br><span class="line">2、复杂的计算(多表join等)</span><br><span class="line">3、数据的更新要实时反馈(update的结果要及时查询)</span><br><span class="line">4、查询结果必须快速</span><br><span class="line">5、视图可以定义参数(ID，时间戳等)</span><br><span class="line">6、视图可维护</span><br></pre></td></tr></table></figure><p>这个类似于实时数仓的Shasta，并没有采用任何预计算或是物化视图，虽然物化视图和预计算可以一定程度的降低查询延迟，但是其数据更新有周期性的延迟、写入时的开销较大以及需求变化大，再加上业务的表非常多，所以导致预计算和物化视图不太现实。</p><p><img src="/2018/04/09/Google-Shasta解读/shasta_architecture.png" alt="Shasta架构"></p><p>Shasta能做到上面提到的3点需求，主要依赖于3个组件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1、TableCache</span><br><span class="line">2、RVL语言</span><br><span class="line">3、UDF Server</span><br></pre></td></tr></table></figure><p>其中RVL(Ralational View Language)语言使得查询表达简单且做了隐士聚合，提高了效率；TableCache在SQL引擎和F1数据库之间做了快照的缓存，且查询时可以通过时间戳和Root ID提高效率；UDF Server独立部署且代码重用，同样提高了效率。</p><h2 id="RVL"><a href="#RVL" class="headerlink" title="RVL"></a>RVL</h2><p><img src="/2018/04/09/Google-Shasta解读/RVL.png" alt="RVL"></p><p>RVL是个查询语言，跟SQL类似，最终也会被编译解析成SQL语句。</p><p>之所以设计这个RVL层，从论文中看主要因为太多的表连接使得写出来的SQL太过复杂；而且表达这种复杂SQL时，对广告业务或销售人员来讲太难了，毕竟需要了解50多张甚至更多的表结构，成本太高；同时，RVL的设计可以对业务进行高层的抽象，即2个表可以join为一个视图模版，同时其他的业务也可以用到这个视图，即代码复用，这个设计也是以使用简单为目的。</p><p>RVL的视图定义还支持参数绑定，因为毕竟它只是个视图定义，所以视图参数化使得查询时逻辑更清晰。</p><p>RVL还有个特点是隐士聚合，即当投影某个measure列时，可以定义好聚合类型，这样分析人员表达复杂的聚合操作时更加容易。</p><p>此外，RVL还做了诸如列剪枝、过滤下推、左连接剪枝等优化。</p><p>总体感觉，RVL的设计初衷是为了简化表达，逻辑清晰，提高效率。毕竟RVL终究还是要解析成SQL去执行的。</p><h2 id="F1查询引擎"><a href="#F1查询引擎" class="headerlink" title="F1查询引擎"></a>F1查询引擎</h2><p>F1是Google内部的分布式MySQL，当SQL提交到F1的Coordinator时，它将请求分为中心化的请求和分布式的请求，即简单的请求直接在F1对应的Server上执行，而复杂的请求则将SQL转换为DAG模型在F1的slave中并行执行。</p><p>F1的查询引擎有下面3个特点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1、hash分区</span><br><span class="line">2、DAG执行计划的缓存</span><br><span class="line">3、外部数据源的优化</span><br></pre></td></tr></table></figure><p>分布式的join消耗很大，采用hash分区可以将计算和数据都在本地进行，这样可以极大的提高join时的效率。</p><p>视图的定义是对业务的高层抽象，因此父视图的执行计划以及数据就可以进行缓存，类似于Oracle中的With语句，即先定义一个子集合，下面的查询如果需要反复使用上边定义的子集合时，表达会很清晰且有数据缓存的优化空间。</p><p>Shasta本身是个计算引擎，存储的数据位于F1、TableCache或者Mesta和Spanner中，因此设计了取数据的插件，加速数据的加载。</p><h2 id="TableCache"><a href="#TableCache" class="headerlink" title="TableCache"></a>TableCache</h2><p>TableCache是F1引擎和F1存储之间的中间件缓存层。通过对TableCache指定元组(table,RootId,timestamp)来加速查询。</p><p>其中，(table,RootId)将F1中的数据行分成了很多的分片；其次数据是懒加载且cache也是分片的；最后timestamp提供多版本的数据，同时根据F1 change history日志进行更新。</p><p>事实上，Shasta的低延迟，主要原因还是在于TableCache的应用，通过将数据以多版本的快照形式存在分布式的缓存中以及数据与计算的本地化，实现了对数据的快速访问。</p><h2 id="UDF服务器"><a href="#UDF服务器" class="headerlink" title="UDF服务器"></a>UDF服务器</h2><p>UDF在SQL中很普通，但是F1中却是独立部署的，这样的好处不但可以复用代码，还可以减少F1引擎的GC压力，同时可以设置不同的并行度。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们从Shasta的论文可以看到，实时数据仓库的实现，如果采用预计算的方式，那么灵活性就不能满足；通过分布式的Cache以及join数据的本地化，使得后计算也成为可能。</p><p>SnappyData的实现思路与Shasta还是有相似之处，内存+本地化存储明细数据，使得完全的后计算既可以支持灵活多变的SQL需求，也可以通过SQL提高效率，还可以通过进一步的优化实现复杂分析下的低延迟的需求。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Shasta系统架构&quot;&gt;&lt;a href=&quot;#Shasta系统架构&quot; class=&quot;headerlink&quot; title=&quot;Shasta系统架构&quot;&gt;&lt;/a&gt;Shasta系统架构&lt;/h2&gt;&lt;p&gt;Google内部广告业务的数据分析，需要满足3方面的需求：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1、查询的延迟要低&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2、查询的表达要简单&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3、查询的结果要及时更新&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="论文" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
  </entry>
  
  <entry>
    <title>SnappyData与Presto,Druid,Kylin,ES的对比-2</title>
    <link href="http://yoursite.com/2018/04/04/SnappyData%E4%B8%8EPresto-Druid-Kylin-ES%E7%9A%84%E5%AF%B9%E6%AF%94-2/"/>
    <id>http://yoursite.com/2018/04/04/SnappyData与Presto-Druid-Kylin-ES的对比-2/</id>
    <published>2018-04-04T04:07:31.000Z</published>
    <updated>2018-04-04T10:29:43.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="OLAP简介"><a href="#OLAP简介" class="headerlink" title="OLAP简介"></a>OLAP简介</h2><p>On-Line Analytical Processing，简称OLAP，即联机分析处理，其主要的功能在于方便大规模数据分析及统计计算，对决策提供参考和支持。</p><p>OLAP发展到现在的阶段，很多的查询分析需求具有以下4种显著的特点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、数据量大</span><br><span class="line">2、高速响应</span><br><span class="line">3、灵活交互</span><br><span class="line">4、多维分析</span><br></pre></td></tr></table></figure><p><img src="/2018/04/04/SnappyData与Presto-Druid-Kylin-ES的对比-2/OLAP-1.png" alt="现代OLAP特点"></p><a id="more"></a><p>根据存储类型，OLAP又分为ROLAP(RelationalOLAP)、MOLAP(MultidimensionalOLAP)以及HOLAP(HybridOLAP)。</p><p>根据处理类型，OLAP又分为MPP架构、搜索引擎架构和预处理架构。</p><p>在开源领域OLAP的解决方案中，包括了诸如Presto、SparkSQL、Impala以及SnappyData等MPP架构和ROLAP的引擎；也包括了Druid和Kylin等预处理架构和MOLAP的引擎；同时还包含了ES这种搜索引擎;除此之外，还有ClickHouse以及IndexR这种列式数据库用于OLAP分析。</p><p>下面我们就这些开源引擎，从上述中以下几个方面进行对比：<strong>数据规模</strong>、<strong>查询性能</strong>、<strong>灵活性</strong>、<strong>易用性</strong>、<strong>处理方式</strong>以及<strong>实时性</strong>进行对比。</p><h2 id="分布式开源OLAP引擎"><a href="#分布式开源OLAP引擎" class="headerlink" title="分布式开源OLAP引擎"></a>分布式开源OLAP引擎</h2><h3 id="基于MPP架构的ROLAP引擎"><a href="#基于MPP架构的ROLAP引擎" class="headerlink" title="基于MPP架构的ROLAP引擎"></a>基于MPP架构的ROLAP引擎</h3><p>Presto、Impala以及Spark SQL，都是利用关系模型来处理OLAP查询，通过并发来提高查询性能。</p><p>这类引擎的优点和缺点如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line">1、支持的数据规模大(非存储引擎)；</span><br><span class="line">2、灵活性高，随意查询数据；</span><br><span class="line">3、易用性强，支持标准SQL以及多表join和窗口函数；</span><br><span class="line">4、处理方式简单，无需预处理，全部后处理，没有冗余数据。</span><br><span class="line"></span><br><span class="line">缺点：</span><br><span class="line">1、性能较差，当查询复杂度高且数据量大时，可能分钟级别的响应。同时其不是存储引擎，因此没有本地存储，当join时shuffle开销大，性能差。</span><br><span class="line">2、实时性较差，不支持数据的实时导入，偏离线处理。</span><br></pre></td></tr></table></figure><p>我们以Spark SQL为例来说明，由于其本身只是个计算引擎，而非存储引擎，导致其需要从外部加载数据，使得数据的实时性得不到保证；同时当涉及多表join时，其查询性能很难得到秒级的响应。</p><p>因此，其实时性和查询性能较弱，所以只适合那些对实时性要求不是很高，但灵活性很强的需要多表join的ad-hoc类查询以及需求变化较频繁的查询。</p><p>目前开源社区出现了一种依托Spark SQL，同时自己存储数据的一类OLAP引擎，比如TiSpark以及SnappyData。</p><p>关于TiSpark项目，其虽然以TiKV为存储减少了数据加载的延迟，使得实时性可以得到保证，但是其在数据量较大时的join，查询响应依然得不到保证；同时对于窗口函数的分析不支持，部分adhoc需求也得不到有效保证。</p><p>关于SnappyData，其也是个存储引擎，而且表join时通过数据存储本地化以及其他优化，有效将性能差、实时性差的缺点避免掉，我们会在最后就SnappyData做个总结。</p><h3 id="预计算引擎与MOLAP"><a href="#预计算引擎与MOLAP" class="headerlink" title="预计算引擎与MOLAP"></a>预计算引擎与MOLAP</h3><p>Kylin是完全的预计算引擎，通过枚举所有维度的组合，建立各种Cube进行提前聚合，以HBase为基础的OLAP引擎。</p><p>Druid则是轻量级的提前聚合(roll-up)，同时根据倒排索引以及bitmap提高查询效率的时间序列数据和存储引擎。</p><p>Kylin的优缺点如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line">1、支持数据规模超大(HBase)</span><br><span class="line">2、易用性强，支持标准SQL</span><br><span class="line">3、性能很高，查询速度很快</span><br><span class="line"></span><br><span class="line">缺点：</span><br><span class="line">1、灵活性较弱，不支持adhoc查询；且没有二级索引，过滤时性能一般；不支持join以及对数据的更新。</span><br><span class="line">2、处理方式复杂，需要定义Cube预计算；当维度超过20个时，存储可能会爆炸式增长；且无法查询明细数据了；维护复杂</span><br><span class="line">3、实时性很差，很多时候只能查询前一天或几个小时前的数据。</span><br></pre></td></tr></table></figure><p>Druid的优缺点如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line">1、支持的数据规模大(本地存储+DeepStorage--HDFS)</span><br><span class="line">2、性能高，列存压缩，预聚合加上倒排索引以及位图索引，秒级查询</span><br><span class="line">3、实时性高，可以通过kafka实时导入数据</span><br><span class="line"></span><br><span class="line">缺点：</span><br><span class="line">1、灵活性适中，虽然维度之间随意组合，但不支持adhoc查询，不能自由组合查询，且丢失了明细数据</span><br><span class="line">2、易用性较差，不支持join，不支持更新，sql支持很弱(有些插件类似于pinot的PQL语言)，只能JSON格式查询；对于去重操作不能精准去重。</span><br><span class="line">3、处理方式复杂，需要流处理引擎将数据join成宽表，维护相对复杂；对内存要求较高。</span><br></pre></td></tr></table></figure><p>因此，Kylin适合对实时数据需求不高，但响应时间较高的查询，且维度较多，需求较为固定的特定查询；而不适合实时性要求高的adhoc类查询。</p><p>Druid适合那种数据量大，对实时性要求高且响应时间短，以及维度较少且需求固定的简单聚合类查询(sum，count，TopN)，多以storm和flink组合进行预处理；而不适合需要join、update和支持SQL和窗口函数等复杂的adhoc查询。</p><p>如果分析人员想用SQL进行复杂的分析操作，那么Druid不适合。</p><h3 id="搜索引擎架构"><a href="#搜索引擎架构" class="headerlink" title="搜索引擎架构"></a>搜索引擎架构</h3><p>ES是典型的搜索引擎类的架构系统，在入库时将数据转换为倒排索引，采用Scatter-Gather计算模型提高查询性能。对于搜索类的查询效果较好，但当数据量较大时，对于Scan类和聚合类为主的查询性能较低。</p><p>ES的优缺点如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line">1、性能较高，支持倒排索引和各种过滤后的聚合查询。</span><br><span class="line">2、实时性强，在文档上建立完索引后，立刻可以查询。</span><br><span class="line">3、处理方式简单，无需预处理</span><br><span class="line"></span><br><span class="line">缺点：</span><br><span class="line">1、支持的数据规模较小，高并发不理想。</span><br><span class="line">2、灵活性差，不支持复杂的adhoc查询</span><br><span class="line">3、易用性差，不支持SQL；DSL成本高，且不能精准去重。</span><br></pre></td></tr></table></figure><p>因此，ES适合那种全文检索，且数据规模较少时过滤条件很多的聚合查询，并发度也不大的场景。</p><p>同样，如果分析人员想用SQL分析，那么也不适合ES。</p><h3 id="纯列存OLAP"><a href="#纯列存OLAP" class="headerlink" title="纯列存OLAP"></a>纯列存OLAP</h3><p>ClickHouse是个列存数据库，保存原始明细数据，通过MergeTree使得数据存储本地化来提高性能，是个单机版超高性能的数据库。</p><p>ClickHouse的优缺点如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line">1、性能高，列存压缩比高，通过索引实现秒级响应</span><br><span class="line">2、实时性强，支持kafka导入</span><br><span class="line">3、处理方式简单，无需预处理，保存明细数据</span><br><span class="line"></span><br><span class="line">缺点：</span><br><span class="line">1、数据规模一般</span><br><span class="line">2、灵活性差，不支持任意的adhoc查询，join的支持不好。</span><br><span class="line">3、易用性较弱，SQL语法不标准，不支持窗口函数等；维护成本高</span><br></pre></td></tr></table></figure><p>因此，ClickHouse适合数据规模不大情况下的单机且单表的数据分析。实际场景有待检验。</p><h3 id="SnappyData"><a href="#SnappyData" class="headerlink" title="SnappyData"></a>SnappyData</h3><p>SnappyData是个计算与存储引擎，全内存、行列混合存储且完全不需预处理，支持SQL与Spark SQL，兼顾MPP的特点且colocate特性使得数据本地化，支持join、列表的update以及窗口函数等任意的adhoc查询。</p><p>SnappyData的优缺点如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line">1、性能高，列存压缩+全内存，数据状态共享，秒级查询</span><br><span class="line">2、实时性强，支持kafka的stream table以及实时导入</span><br><span class="line">3、处理方式简单，无需预处理，保存明细数据，数据本地存储</span><br><span class="line">4、灵活性高，是个sql数据库，支持任意字段的查询、update以及窗口函数和复杂的adhoc查询</span><br><span class="line">5、易用性强，支持标准SQL和Spark SQL，精准去重，支持各种分许函数</span><br><span class="line"></span><br><span class="line">缺点：</span><br><span class="line">1、数据规模中等，由于全内存导致成本较高，且需要关注GC问题</span><br><span class="line">2、维护成本高</span><br></pre></td></tr></table></figure><p>因此，SnappyData适合那种数据规模中等(PB以下)，需求变化加多，实时性要求较高、响应时间较短且复杂的窗口函数类查询；同时适合查询明细数据以及探索式的adhoc查询。</p><p>如果数据规模不大，且希望找到一种简单易用且实时性要求高的多维OLAP引擎，最重要的是可供分析人员使用的SQL的引擎，那么SnappyData比较适合。前提是需要在成本与效率之间做个平衡，SQL固然能提高开发效率，但内存较大的服务器成本也确实相对较高。</p><h2 id="引擎对比"><a href="#引擎对比" class="headerlink" title="引擎对比"></a>引擎对比</h2><p><img src="/2018/04/04/SnappyData与Presto-Druid-Kylin-ES的对比-2/OLAP-2.png" alt="对比"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;OLAP简介&quot;&gt;&lt;a href=&quot;#OLAP简介&quot; class=&quot;headerlink&quot; title=&quot;OLAP简介&quot;&gt;&lt;/a&gt;OLAP简介&lt;/h2&gt;&lt;p&gt;On-Line Analytical Processing，简称OLAP，即联机分析处理，其主要的功能在于方便大规模数据分析及统计计算，对决策提供参考和支持。&lt;/p&gt;
&lt;p&gt;OLAP发展到现在的阶段，很多的查询分析需求具有以下4种显著的特点：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1、数据量大&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2、高速响应&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3、灵活交互&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4、多维分析&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;/2018/04/04/SnappyData与Presto-Druid-Kylin-ES的对比-2/OLAP-1.png&quot; alt=&quot;现代OLAP特点&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="对比" scheme="http://yoursite.com/categories/%E5%AF%B9%E6%AF%94/"/>
    
    
  </entry>
  
  <entry>
    <title>SnappyData架构</title>
    <link href="http://yoursite.com/2018/03/21/SnappyData%E6%9E%B6%E6%9E%84/"/>
    <id>http://yoursite.com/2018/03/21/SnappyData架构/</id>
    <published>2018-03-21T02:31:02.000Z</published>
    <updated>2018-03-23T03:17:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>SnappyData既是个存储引擎，也是个计算引擎。这篇文章主要针对SnappyData的核心组件与整体架构进行讲解，并涉及数据模型、数据注入流程、如何响应SQL请求、集群角色和集群管理等内容</p><h3 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h3><p><img src="/2018/03/21/SnappyData架构/components.png" alt=""></p><p>SnappyData融合了GemFire与Spark，其中，图中灰色背景的来源于Spark中的组件。</p><h3 id="说存储"><a href="#说存储" class="headerlink" title="说存储"></a>说存储</h3><a id="more"></a><p>SnappyData中的数据既可以采用行存，也可以设计为列存。行存可以设置分区和全局复制(各个节点中都有一份)，列存仅仅支持分区(基于hash)。</p><p>不管是行存还是列存，数据都是在内存中进行存储的，且可以设置1个或多个副本。内存中既可以使用on heap，也可以使用off-heap(只有企业版才支持)。</p><p>如果采用行存，那么内存的消耗势必会更多些，但是它很适合随机DML或者基于点的select查询等OLTP操作。如果采用列表，那么数据会被存储在连续的内存中并进行压缩。</p><p>其中列存是从Spark RDD中派生而来，遵循着Spark DataSource的访问模型，并且允许压缩。其压缩算法采用的是<a href="https://zh.wikipedia.org/wiki/%E6%B8%B8%E7%A8%8B%E7%BC%96%E7%A0%81" target="_blank" rel="noopener"><strong>游程编码(RLE)</strong></a>和<strong>字典编码</strong>的方式。<br>具体来说，就是对于整形的数据，会根据RLE进行压缩，对于String类型的数据，则会采用字典编码进行压缩。</p><p><img src="/2018/03/21/SnappyData架构/column.png" alt=""></p><p>而行存则可以创建索引，支持对于主键与索引字段的快速读写。一般情况下，行表的访问都是通过主键完成，通过对key进行hash运算，很快可以访问到其内存中的地址。</p><p><img src="/2018/03/21/SnappyData架构/row.png" alt=""></p><p>通常，设计行表用于OLTP事务操作，而设计列表的目的主要用于OLAP分析。</p><p>关于行表和列表的DDL语句，可以参考官方文档:<a href="https://snappydatainc.github.io/snappydata/sql_reference/" target="_blank" rel="noopener">SQL Reference Guide</a>。</p><h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4><p>列表有个区别于Spark RDD的显著特点：可变性。即可以对SnappyData中的列表进行点更新或者批量更新等DML操作，这是因为GemFire的作用。</p><p>通常批量的update和批量的insert效率会更高，例如执行一个包含10万条数据的update语句，比10万个只包含1条数据的update语句效率要高的多。</p><p>列表主要由2个组件组成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、delta row buffer</span><br><span class="line">2、列存数据</span><br></pre></td></tr></table></figure><p>首先，delta row buffer是一个行存，它具有与其列表相同的分区策略，它的特点是高速写入。</p><p>当数据写入到列表时，它在内部的写入步骤如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、数据首先会被写入到这个高速的row buffer中</span><br><span class="line">2、当row buffer大小达到设置的大小(snappydata.column.batchSize,默认24M)或者row buffer的行数大于设定的行数(snappydata.column.maxDeltaRows，默认10000行)时，数据会被压缩并最终写入到列表中。</span><br></pre></td></tr></table></figure><p>其次，delta row buffer中的delta，体现在它的内部结构上。它实际上是一个<strong>合并队列</strong>。所谓合并的含义，是指对同一列数据进行多个操作，它只会保留最终的状态。</p><p>举例来说，假如对某个记录先进行insert或者update操作，在row buffer被刷到列表前，又进行delete操作，那么实际上这个数据会从这个队列中直接删除；又或者某个列上进行连续2个update操作，那么这个row buffer最终只会将最后的那个update的值写入到列表中。</p><p>最后，SnappyData还扩展了Spark的Catalyst，使得在列表上进行select操作时，会将delta row buffer中的数据merge到列表中，以保证查询到最新的数据。</p><p>同时，对于同一列上多个并发的DML操作，SnappyData采用了<strong>copy-on-write</strong>来保证数据一致性。</p><h4 id="DDL的扩展"><a href="#DDL的扩展" class="headerlink" title="DDL的扩展"></a>DDL的扩展</h4><p>由于融合了GemFire和Spark，因此在创建表时，SnappyData对标准DDL语句进行了扩展，具体如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1、COLOCATE_WITH:COLOCATE_WITH &#123;exist_table&#125;语法的含义是对于新建的表，与exist_table具有相同的分区键，且相同键存储在同一个节点上，即数据存储本地化。这样做的好处是当2个表发生基于key的join时，那些非常耗资源的hash join就不用跨节点进行数据传输(广播)，而是在本地进行join。这个设计思路非常像关系型数据库Oracle中的cluster存储。这种数据存储本地化的特点，也是SnappyData在做join时比Spark快很多的原因之一。</span><br><span class="line"></span><br><span class="line">2、PARTITION_BY:PARTITION_BY &#123;COLUMN&#125;语法的含义是按某列进行分区，当然也可以指定多个列作为组合。行表如果没有指定分区键，那么将是一张全局复制表；列表如果没有指定，那么内部也会有个默认的分区。列表中的分区遵循Spark Catalyst的hash分区，使得join时最小化shuffle。</span><br><span class="line"></span><br><span class="line">3、BUCKETS：分区的个数。默认是128个，最小的数据存储单元。本地存储，这个值可以设置为集群core数量的2倍。</span><br><span class="line"></span><br><span class="line">4、REDUNDANCY：分区的副本数，如果设置为0，表示没有副本；如果设置大于0，则会为partition创建对应的副本数，以防止member失败，达到数据的高可用性的目的。</span><br><span class="line"></span><br><span class="line">5、EVICTION_BY：驱逐，很像Flink window中的eviction设置。列表上默认的参数值是LRUHEAPPERCENT，根据LRU算法达到阀值时，开始将内存中的较“冷”的数据溢出到本地磁盘：SnappyStore存储。</span><br><span class="line"></span><br><span class="line">6、PERSISTENCE：持久化。默认是允许持久化的，数据会从内存中持久化到本地SnappyStore存储中，当重启memeber时，SnappyData会自动从本地的SnappyStore存储中恢复数据。</span><br><span class="line"></span><br><span class="line">7、OVERFLOW：溢出，默认是true，即允许溢出。如果没有指定PERSISTENCE，且将OVERFLOW设置为false，那么当失败时，内存中的数据将被丢失。</span><br><span class="line"></span><br><span class="line">8、DISKSTORE：为持久化的数据或溢出的数据提供持久化目录。可以通过CREATE DISKSTORE为表提前创建出本地文件目录，可以指定文件、配置数据收缩、配置数据异步到磁盘的频率等等.</span><br><span class="line"></span><br><span class="line">9、EXPIRE：过期时间。为了提高内存使用率，对于很老的历史数据，可以通过设置过期时间使得超过阀值的行数据过期。但是过期参数只适合行表。</span><br><span class="line"></span><br><span class="line">10、COLUMN_BATCH_SIZE：刚才提到了，delta row buffer的batch大小，默认24MB。超过阀值就会写到列表。</span><br><span class="line"></span><br><span class="line">11、COLUMN_MAX_DELTA_ROWS：delta row buffer的最大行数，默认10000行。超过阀值会写到列表。</span><br></pre></td></tr></table></figure><p>除此之外，列表上也有些限制，例如不能设置主键、唯一约束、索引、不适合过期设置，LRUCount的驱逐不适合，<strong>READ_COMMITTED</strong>和<strong>REPEATABLE_READ</strong>的隔离级别不适合列表。</p><h3 id="API及其他组件"><a href="#API及其他组件" class="headerlink" title="API及其他组件"></a>API及其他组件</h3><p>SnappyData中支持2种API：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、标准SQL+Spark SQL</span><br><span class="line">2、Spark API</span><br></pre></td></tr></table></figure><p>我们可以把SnappyData当做一个SQL数据库，Spark SQL Catalyst会解析SQL，生成可执行的物理执行计划并代码生成Spark的job去执行。但是，并不是所有的SQL语句都交给Spark去解析。对于行表上快速的点update这种OLTP操作，会由P2P网络负责，同时直接追加到列表上的点insert操作，也会交给GemFire处理，这样做的目的不用通过Spark Job执行，加快执行速度。</p><p>P2P(peer-to-peer)网络组件的作用有3个：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1、发现服务：检测新成员的加入或member失败。</span><br><span class="line">2、副本一致性：同步复制副本数据。</span><br><span class="line">3、快速点更新</span><br></pre></td></tr></table></figure><p>客户端可以通过JDBC或ODBC(企业版才支持)连接到SnappyData。除此之外，流处理功能则依赖Spark Streaming组件实现。</p><p>SDE是Synopsis Data Engine的简称，核心要素是通过分层采样等方法对超大规模的历史数据建立采样表，通过允许丢失一定比例的准确性，达到快速返回结果的目的。这也是流处理概念的核心：在准确性和低延迟之间做的一种取舍。这种方法也叫AQP(approximate query processing)，即近似查询处理，但是只有企业版中才支持。</p><h3 id="数据流程"><a href="#数据流程" class="headerlink" title="数据流程"></a>数据流程</h3><p><img src="/2018/03/21/SnappyData架构/ingestion.png" alt=""></p><p>图中共有6个步骤，表明了数据从导入到查询的通常步骤：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1、原始数据导入：一旦集群建立，就可以从外部数据源(HDFS、Hive、MySQL、Oracle、csv等)中导入历史数据；行存或列存根据需求而定。</span><br><span class="line"></span><br><span class="line">2、流式数据实时注入：你可以将实时产生的数据插入到SnappyData，可以采用Spark Streaming的DStream将批量的数据导入，当然也可以采用其他框架(Flink等)来批量导入实时数据。</span><br><span class="line"></span><br><span class="line">3、实时查询：当实时数据注入后，你便可以用SQL进行复杂的、多维度聚合的数据(实时+历史)。</span><br><span class="line"></span><br><span class="line">4、delta row buffer：在数据被写入列表前，会先写到高速的row buffer中，且它具有合并的功能，在老化到(根据COLUMN_BATCH_SIZE和COLUMN_MAX_DELTA_ROWS)列表前，只会存储最终的状态。</span><br><span class="line"></span><br><span class="line">5、防止OOM：表可以设置为持久化到磁盘和溢出到磁盘(LRU算法)，以防止OOM。而且，当历史数据过大或者不再查询时，可以将这些数据写到HDFS中。</span><br><span class="line"></span><br><span class="line">6、ad-hoc查询：数据注入后，用户既可以对实时数据进行交互式的查询，也可以结合历史数据进行OLAP分析。用户也可以使用AQP功能，AQP功能会牺牲准确性从而达到低延迟的目的，但AQP只在企业版中支持。</span><br></pre></td></tr></table></figure><h3 id="SnappyData角色"><a href="#SnappyData角色" class="headerlink" title="SnappyData角色"></a>SnappyData角色</h3><p><img src="/2018/03/21/SnappyData架构/architecture.png" alt=""></p><p>SnappyData集群是有3种不同的角色组成的P2P网络：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1、Locator：发现新成员的加入，接受客户端请求，失败恢复等。为了高可用，通常locator有2个，一主一备。</span><br><span class="line"></span><br><span class="line">2、Lead Node：相当于Spark Driver的角色，负责集群管理并分发Spark Job给Executor；通常也是一主一备。</span><br><span class="line"></span><br><span class="line">3、Data Servers：存储数据；同时扮演Executor的角色执行任务计算。Server角色负责对locator发送的请求进行SQL解析，如果数据只涉及本节点，那么无需发送给lead，直接在本地进行计算；否则发送给lead，由lead负责分发job到各个对应的节点进行计算。</span><br></pre></td></tr></table></figure><p>上图中我们可以看到，客户端通过JDBC或者ODBC，指定locator的地址进行连接；locator会将客户端的连接分发到不同的server；server负责解析SQL，并判断是否交给lead进行job部署,这里有些SQL语句是不需要由lead生成spark job的，例如show tables，行表上的操作，insert into XX values(xx)单点插入等；如果是复杂的SQL，则交给lead进行分发，具体的执行则分发到各个server执行计算。</p><h3 id="混合集群管理器"><a href="#混合集群管理器" class="headerlink" title="混合集群管理器"></a>混合集群管理器</h3><p><img src="/2018/03/21/SnappyData架构/hybrid_cluster.png" alt=""></p><p>Spark主要是用于批处理操作，通常对大量数据的处理(包括多表join等)时间都比较高。但是这对于SnappyData来讲无法接受，好在SnappyData利用了全内存、与Spark存储格式一致、colocate数据本地化等特点，得以将延迟降低到秒级或者毫秒级。</p><p>除此之外，SnappyData还必须满足额外的需求才可以作为一个实时的SQL数据库使用，例如高并发、状态共享、高可用以及数据一致性。</p><h4 id="高并发"><a href="#高并发" class="headerlink" title="高并发"></a>高并发</h4><p>面对高并发，SnappyData将客户端所有的请求分成2类：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、低延迟的请求</span><br><span class="line">2、高延迟的请求</span><br></pre></td></tr></table></figure><p>对于低延迟的请求，SnappyData会跳过Spark的调度，而是直接由GemFireXD处理数据，例如上边提到的行表的操作，点插入，show或describe命令等；</p><p>而对于高延迟的请求，则会根据Spark的Fair调度机制分发到各个server执行计算，例如列表上的select或者点更新，批量DML等。</p><h4 id="状态共享"><a href="#状态共享" class="headerlink" title="状态共享"></a>状态共享</h4><p>SnappyData是一个Shared Nothing存储，完全的分布式本地存储。但是不同的job之间，数据是可以共享的。原因就是因为SnappyData本身也是个存储引擎，其数据完全驻留在内存中，因此天然具有状态共享的优点。</p><h4 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h4><p>发现服务：SnappyData是个P2P网络，因此它提供了发现服务，即提供一个包括lead和server的列表。</p><p>组协调器：最先加入的成员自然成为了coordinator角色，这个角色会不断的检测当前的member，并与初始的列表进行对比以确保所有成员是可用的。当有新的成员加入时，根据发现服务，coordinator会将新加入的成员加入列表并把一些数据同步到其节点中。</p><p>失败检测：对于节点失败是很容易检测到的；而对于网络分裂或者脑裂情况，就会比较复杂一些。SnappyData通过UDP neighbor ping等机制进行多次检测，以确定疑似的失败是否是真正的失败。</p><p>HA：SnappyData另一个高可用的地方表现在其Lead节点的HA，即可配置primary角色和standby角色。选举则根据分布式锁服务，先到的就是primary。</p><h4 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h4><p>SnappyData提供了<strong>read committed</strong>和<strong>repeatable read</strong>两种事务隔离级别。在写入发生时，会对所有的副本加排他锁，这里有个假设就是很少出现不能获得排他写锁的情况，提交的时候会应用到所有的副本。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>到此为止，关于SnappyData的架构，基本就讲完了。我们后续会继续根据SnappyData的使用写一些应用类的博客。</p><p>也欢迎大家加入<strong><a href="http://47.104.162.24/" target="_blank" rel="noopener">SnappyData专业中文社区</a></strong>和<strong>SnappyData中国用户组</strong>微信群进行交流。</p><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p><a href="https://www.snappydata.io/snappy-industrial" target="_blank" rel="noopener">SnappyData: Streaming,Transactions,and Interactive<br>Analytics in a Unified Engine</a></p><p><a href="https://snappydatainc.github.io/snappydata/architecture/core_components/" target="_blank" rel="noopener">官方文档</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SnappyData既是个存储引擎，也是个计算引擎。这篇文章主要针对SnappyData的核心组件与整体架构进行讲解，并涉及数据模型、数据注入流程、如何响应SQL请求、集群角色和集群管理等内容&lt;/p&gt;
&lt;h3 id=&quot;核心组件&quot;&gt;&lt;a href=&quot;#核心组件&quot; class=&quot;headerlink&quot; title=&quot;核心组件&quot;&gt;&lt;/a&gt;核心组件&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2018/03/21/SnappyData架构/components.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;SnappyData融合了GemFire与Spark，其中，图中灰色背景的来源于Spark中的组件。&lt;/p&gt;
&lt;h3 id=&quot;说存储&quot;&gt;&lt;a href=&quot;#说存储&quot; class=&quot;headerlink&quot; title=&quot;说存储&quot;&gt;&lt;/a&gt;说存储&lt;/h3&gt;
    
    </summary>
    
      <category term="科普" scheme="http://yoursite.com/categories/%E7%A7%91%E6%99%AE/"/>
    
    
  </entry>
  
  <entry>
    <title>SnappyData与TiDB,Spark,Flink的对比-1</title>
    <link href="http://yoursite.com/2018/03/19/SnappyData%E4%B8%8ETiDB,Spark,Flink%E7%9A%84%E5%AF%B9%E6%AF%94-1/"/>
    <id>http://yoursite.com/2018/03/19/SnappyData与TiDB,Spark,Flink的对比-1/</id>
    <published>2018-03-19T08:55:31.000Z</published>
    <updated>2018-03-20T02:09:09.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="SnappyData是什么？"><a href="#SnappyData是什么？" class="headerlink" title="SnappyData是什么？"></a>SnappyData是什么？</h3><p><strong>SnappyData</strong>是一个开源的内存分布式存储与计算引擎，提供实时的、HTAP(OLTP+OLAP)场景的解决方案，融合了Apache Spark与GemFire数据库，以多种数据模型提供复杂的、实时的、多维度的OLAP分析，完全支持标准SQL与Spark SQL。</p><p>分析人员只需通过SQL便可对实时数据进行低延迟且高准确性的分析工作。</p><h3 id="SnappyData的特性"><a href="#SnappyData的特性" class="headerlink" title="SnappyData的特性"></a>SnappyData的特性</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1、分布式存储+计算引擎</span><br><span class="line">2、完全基于内存</span><br><span class="line">3、融合了Gemfire与Apache Spark的特性</span><br><span class="line">4、支持行存，且支持列存(压缩)</span><br><span class="line">5、对行存与列存都支持DML操作</span><br><span class="line">6、区分开源版本与闭源版本(支持off-heap与AQP功能)</span><br><span class="line">7、存储时可指定关联关系，使得数据本地化(colocate)，多表join性能是Spark的20倍+</span><br><span class="line">8、完全兼容Spark，支持标准SQL与Spark SQL</span><br><span class="line">9、对实时数据的处理只需用标准SQL或Spark SQL即可，同时由于其存储明细数据，使得对实时数据的处理既支持乱序又支持Retraction，非常适合ad-hoc类查询</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="与TiDB对比"><a href="#与TiDB对比" class="headerlink" title="与TiDB对比"></a>与TiDB对比</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TiDB是基于KV的行存；SnappyData支持列存。</span><br><span class="line">TiDB更适合OLTP事务；SnappyData更适合OLAP分析。</span><br><span class="line">TiDB存储于RocksDB；SnappyData完全内存，且支持overflow。</span><br><span class="line">TiDB支持DQL、DML与DDL；SnappyData也支持DQL、DML与DDL。</span><br><span class="line">TiDB支持分布式的多副本；SnappyData也支持多副本。</span><br><span class="line">TiSpark基于Spark处理复杂SQL；SnappyData存储采用与Spark一样的存储格式，省去加载的时间，同时支持colocate，使得join时性能提升2个级别</span><br></pre></td></tr></table></figure><h3 id="SnappyData相比于Spark的优势"><a href="#SnappyData相比于Spark的优势" class="headerlink" title="SnappyData相比于Spark的优势"></a>SnappyData相比于Spark的优势</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Spark的RDD不可变；SnappyData可变(Gemfire)，因此SnappyData的数据支持DML</span><br><span class="line">Spark需要从外部数据源加载数据；SnappyData不需要加载，存储格式与Spark的DataFrame一致</span><br><span class="line">Spark计算时基于内存；SnappyData计算转换为Spark Job，也是基于内存(不是所有的SQL都走Spark Job)</span><br><span class="line">Spark对于多表join，涉及跨机器join，性能受限；SnappyData存储支持表间colocate，join发生在机器本地，性能提高</span><br></pre></td></tr></table></figure><h3 id="SnappyData相比于Flink的优势"><a href="#SnappyData相比于Flink的优势" class="headerlink" title="SnappyData相比于Flink的优势"></a>SnappyData相比于Flink的优势</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Flink流处理的API是DataStream，学习成本较高；SnappyData API支持标准SQL与Spark SQL，学习成本较低。</span><br><span class="line">Flink的Stream SQL目前支持功能有限，尤其是流表join与双流join</span><br><span class="line">Flink在单流的汇总功能强大，双流join欠缺准确性；SnappyData支持多个表的join，且准确性极高</span><br><span class="line">Flink的处理延时极低(毫秒级)；SnappyData处理延迟同样极低(毫秒级)</span><br><span class="line">Flink处理一个需求就需要单独一个job；SnappyData简单很多，一个SQL对应一个需求，效率极高</span><br><span class="line">Flink支持乱序及Retraction，但是已经发出的结果不能更改；SnappyData由于存储明细数据，因此也支持乱序与Retraction，同时对于已经发出的结果，同样可以更改(客户端只需再次调用一遍SQL即可)</span><br><span class="line">Flink实时处理不能很好的关联大量的历史数据；SnappyData随意关联历史数据，通过SQL不但可以查询实时数据，同样可查询历史数据</span><br></pre></td></tr></table></figure><h3 id="SnappyData的劣势"><a href="#SnappyData的劣势" class="headerlink" title="SnappyData的劣势"></a>SnappyData的劣势</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、尽管列存支持压缩，从而大幅度减少数据量，同时可以横向扩展，但是内存空间的使用仍然使得成本较高</span><br><span class="line">2、存储+计算都在内存进行，且Spark Job的运行基于JVM，要注意防止内存不足的情况出现</span><br><span class="line">3、社区不够活跃</span><br><span class="line">4、对于PB及以上的数据规模，即使横向扩展也不太适合这种规模</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;SnappyData是什么？&quot;&gt;&lt;a href=&quot;#SnappyData是什么？&quot; class=&quot;headerlink&quot; title=&quot;SnappyData是什么？&quot;&gt;&lt;/a&gt;SnappyData是什么？&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;SnappyData&lt;/strong&gt;是一个开源的内存分布式存储与计算引擎，提供实时的、HTAP(OLTP+OLAP)场景的解决方案，融合了Apache Spark与GemFire数据库，以多种数据模型提供复杂的、实时的、多维度的OLAP分析，完全支持标准SQL与Spark SQL。&lt;/p&gt;
&lt;p&gt;分析人员只需通过SQL便可对实时数据进行低延迟且高准确性的分析工作。&lt;/p&gt;
&lt;h3 id=&quot;SnappyData的特性&quot;&gt;&lt;a href=&quot;#SnappyData的特性&quot; class=&quot;headerlink&quot; title=&quot;SnappyData的特性&quot;&gt;&lt;/a&gt;SnappyData的特性&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1、分布式存储+计算引擎&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2、完全基于内存&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3、融合了Gemfire与Apache Spark的特性&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4、支持行存，且支持列存(压缩)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5、对行存与列存都支持DML操作&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6、区分开源版本与闭源版本(支持off-heap与AQP功能)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7、存储时可指定关联关系，使得数据本地化(colocate)，多表join性能是Spark的20倍+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8、完全兼容Spark，支持标准SQL与Spark SQL&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9、对实时数据的处理只需用标准SQL或Spark SQL即可，同时由于其存储明细数据，使得对实时数据的处理既支持乱序又支持Retraction，非常适合ad-hoc类查询&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="对比" scheme="http://yoursite.com/categories/%E5%AF%B9%E6%AF%94/"/>
    
    
  </entry>
  
  <entry>
    <title>欢迎来到SnappyData中文博客</title>
    <link href="http://yoursite.com/2018/03/19/%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E4%B8%AD%E6%96%87%E5%8D%9A%E5%AE%A2/"/>
    <id>http://yoursite.com/2018/03/19/欢迎来到中文博客/</id>
    <published>2018-03-19T04:12:57.000Z</published>
    <updated>2018-04-03T03:07:41.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="关于SnappyData"><a href="#关于SnappyData" class="headerlink" title="关于SnappyData"></a>关于SnappyData</h3><p><strong>SnappyData</strong>是一个<strong>开源的</strong>、<strong>内存分布式**</strong>存储<strong>与</strong>计算引擎<strong>，提供</strong>实时的<strong>、</strong>HTAP(OLTP+OLAP)**场景的解决方案。</p><p>它融合了<strong>Apache Spark</strong>与<strong>GemFire</strong>数据库，以多种数据模型(行表+列表)提供复杂的、实时的、多维度的OLAP分析与OLTP事务处理，完全支持<strong>标准SQL</strong>与<strong>Spark SQL</strong>。</p><p>分析人员只需通过SQL便可对实时数据进行<strong>低延迟</strong>与<strong>高准确性</strong>(对<strong>乱序的处理与Retraction的支持</strong>)的分析工作。</p><a id="more"></a><h3 id="SnappyData中文社区"><a href="#SnappyData中文社区" class="headerlink" title="SnappyData中文社区"></a>SnappyData中文社区</h3><p><a href="http://snappydata.club/" target="_blank" rel="noopener">SnappyData专业中文社区</a></p><h3 id="博客支持"><a href="#博客支持" class="headerlink" title="博客支持"></a>博客支持</h3><p>该中文博客由<code>美团旅行-住宿事业部-经营效率组</code>维护，并不定期发布<strong>SnappyData</strong>相关博客。</p><h3 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h3><p><a href="https://www.snappydata.io/community" target="_blank" rel="noopener">SnappyData官方社区</a></p><p><a href="https://www.snappydata.io/blog" target="_blank" rel="noopener">SnappyData官方博客</a></p><p><a href="https://snappydatainc.github.io/snappydata/" target="_blank" rel="noopener">SnappyData官方文档</a></p><p><a href="https://www.snappydata.io/" target="_blank" rel="noopener">SnappyData官方网站</a></p><p><a href="http://snappydata.club/" target="_blank" rel="noopener">SnappyData专业中文社区</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;关于SnappyData&quot;&gt;&lt;a href=&quot;#关于SnappyData&quot; class=&quot;headerlink&quot; title=&quot;关于SnappyData&quot;&gt;&lt;/a&gt;关于SnappyData&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;SnappyData&lt;/strong&gt;是一个&lt;strong&gt;开源的&lt;/strong&gt;、&lt;strong&gt;内存分布式**&lt;/strong&gt;存储&lt;strong&gt;与&lt;/strong&gt;计算引擎&lt;strong&gt;，提供&lt;/strong&gt;实时的&lt;strong&gt;、&lt;/strong&gt;HTAP(OLTP+OLAP)**场景的解决方案。&lt;/p&gt;
&lt;p&gt;它融合了&lt;strong&gt;Apache Spark&lt;/strong&gt;与&lt;strong&gt;GemFire&lt;/strong&gt;数据库，以多种数据模型(行表+列表)提供复杂的、实时的、多维度的OLAP分析与OLTP事务处理，完全支持&lt;strong&gt;标准SQL&lt;/strong&gt;与&lt;strong&gt;Spark SQL&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;分析人员只需通过SQL便可对实时数据进行&lt;strong&gt;低延迟&lt;/strong&gt;与&lt;strong&gt;高准确性&lt;/strong&gt;(对&lt;strong&gt;乱序的处理与Retraction的支持&lt;/strong&gt;)的分析工作。&lt;/p&gt;
    
    </summary>
    
      <category term="科普" scheme="http://yoursite.com/categories/%E7%A7%91%E6%99%AE/"/>
    
    
  </entry>
  
</feed>

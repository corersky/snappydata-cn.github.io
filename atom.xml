<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SnappyData中文博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-03-21T11:35:56.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>经营效率小队</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>SnappyData架构</title>
    <link href="http://yoursite.com/2018/03/21/SnappyData%E6%9E%B6%E6%9E%84/"/>
    <id>http://yoursite.com/2018/03/21/SnappyData架构/</id>
    <published>2018-03-21T02:31:02.000Z</published>
    <updated>2018-03-21T11:35:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>SnappyData既是个存储引擎，也是个计算引擎。这篇文章主要针对SnappyData的核心组件进行讲解。</p><h3 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h3><p><img src="/2018/03/21/SnappyData架构/components.png" alt=""></p><p>SnappyData融合了GemFire与Spark，其中，图中灰色背景的来源于Spark中的组件。</p><h3 id="说存储"><a href="#说存储" class="headerlink" title="说存储"></a>说存储</h3><p>SnappyData中的数据既可以采用行存，也可以设计为列存。行存可以设置分区和全局复制(各个节点中都有一份)，列存仅仅支持分区(基于hash)。</p><p>不管是行存还是列存，数据都是在内存中进行存储的，且可以设置1个或多个副本。内存中既可以使用on heap，也可以使用off-heap(只有企业版才支持)。</p><p>如果采用行存，那么内存的消耗势必会更多些，但是它很适合随机DML或者基于点的select查询等OLTP操作。如果采用列表，那么数据会被存储在连续的内存中并进行压缩。</p><p>其中列存是从Spark RDD中派生而来，遵循着Spark DataSource的访问模型，并且允许压缩。其压缩算法采用的是<a href="https://zh.wikipedia.org/wiki/%E6%B8%B8%E7%A8%8B%E7%BC%96%E7%A0%81" target="_blank" rel="noopener"><strong>游程编码(RLE)</strong></a>和<strong>字典编码</strong>的方式。<br>具体来说，就是对于整形的数据，会根据RLE进行压缩，对于String类型的数据，则会采用字典编码进行压缩。</p><p><img src="/2018/03/21/SnappyData架构/column.png" alt=""></p><p>而行存则可以创建索引，支持对于主键与索引字段的快速读写。一般情况下，行表的访问都是通过主键完成，通过对key进行hash运算，很快可以访问到其内存中的地址。</p><p><img src="/2018/03/21/SnappyData架构/row.png" alt=""></p><p>通常，设计行表用于OLTP事务操作，而设计列表的目的主要用于OLAP分析。</p><p>关于行表和列表的DDL语句，可以参考官方文档:<a href="https://snappydatainc.github.io/snappydata/sql_reference/" target="_blank" rel="noopener">SQL Reference Guide</a>。</p><h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4><p>列表有个区别于Spark RDD的显著特点：可变性。即可以对SnappyData中的列表进行点更新或者批量更新等DML操作，这是因为GemFire的作用。</p><p>通常批量的update和批量的insert效率会更高，例如执行一个包含10万条数据的update语句，比10万个只包含1条数据的update语句效率要高的多。</p><p>列表主要由2个组件组成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、delta row buffer</span><br><span class="line">2、列存数据</span><br></pre></td></tr></table></figure><p>首先，delta row buffer是一个行存，它具有与其列表相同的分区策略，它的特点是高速写入。</p><p>当数据写入到列表时，它在内部的写入步骤如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、数据首先会被写入到这个高速的row buffer中</span><br><span class="line">2、当row buffer大小达到设置的大小(snappydata.column.batchSize,默认24M)或者row buffer的行数大于设定的行数(snappydata.column.maxDeltaRows，默认10000行)时，数据会被压缩并最终写入到列表中。</span><br></pre></td></tr></table></figure><p>其次，delta row buffer中的delta，体现在它的内部结构上。它实际上是一个<strong>合并队列</strong>。所谓合并的含义，是指对同一列数据进行多个操作，它只会保留最终的状态。</p><p>举例来说，假如对某个列先进行insert或者update操作，在row buffer被刷到列表前，又进行delete操作，那么实际上这个数据会从这个队列中直接删除；又或者某个列上进行连续2个update操作，那么这个row buffer最终只会将最后的那个update的值写入到列表中。</p><p>最后，SnappyData还扩展了Spark的Catalyst，使得在列表上进行select操作时，会将delta row buffer中的数据merge到列表中，以保证查询到最新的数据。</p><p>同时，对于同一列上多个并发的DML操作，SnappyData采用了<strong>copy-on-write</strong>来保证数据一致性。</p><h4 id="DDL的扩展"><a href="#DDL的扩展" class="headerlink" title="DDL的扩展"></a>DDL的扩展</h4><p>由于融合了GemFire和Spark，因此在创建表时，SnappyData对标准DDL语句进行了扩展，具体如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1、COLOCATE_WITH:COLOCATE_WITH &#123;exist_table&#125;语法的含义是对于新建的表，与exist_table具有相同的分区键，且相同键存储在同一个节点上，即数据存储本地化。这样做的好处是当2个表发生基于key的join时，那些非常耗资源的hash join就不用跨节点进行数据传输(广播)，而是在本地进行join。这个设计思路非常像关系型数据库Oracle中的cluster存储。这种数据存储本地化的特点，也是SnappyData在做join时比Spark快很多的原因之一。</span><br><span class="line"></span><br><span class="line">2、PARTITION_BY:PARTITION_BY &#123;COLUMN&#125;语法的含义是按某列进行分区，当然也可以指定多个列作为组合。行表如果没有指定分区键，那么将是一张全局复制表；列表如果没有指定，那么内部也会有个默认的分区。列表中的分区遵循Spark Catalyst的hash分区，使得join时最小化shuffle。</span><br><span class="line"></span><br><span class="line">3、BUCKETS：分区的个数。默认是128个，最小的数据存储单元。本地存储，这个值可以设置为集群core数量的2倍。</span><br><span class="line"></span><br><span class="line">4、REDUNDANCY：分区的副本数，如果设置为0，表示没有副本；如果设置大于0，则会为partition创建对应的副本数，以防止member失败，达到数据的高可用性的目的。</span><br><span class="line"></span><br><span class="line">5、EVICTION_BY：驱逐，很像Flink window中的eviction设置。列表上默认的参数值是LRUHEAPPERCENT，根据LRU算法达到阀值时，开始将内存中的较“冷”的数据溢出到本地磁盘：SnappyStore存储。</span><br><span class="line"></span><br><span class="line">6、PERSISTENCE：持久化。默认是允许持久化的，数据会从内存中持久化到本地SnappyStore存储中，当重启memeber时，SnappyData会自动从本地的SnappyStore存储中恢复数据。</span><br><span class="line"></span><br><span class="line">7、OVERFLOW：溢出，默认是true，即允许溢出。如果没有指定PERSISTENCE，且将OVERFLOW设置为false，那么当失败时，内存中的数据将被丢失。</span><br><span class="line"></span><br><span class="line">8、DISKSTORE：为持久化的数据或溢出的数据提供持久化目录。可以通过CREATE DISKSTORE为表提前创建出本地文件目录，可以指定文件、配置数据收缩、配置数据异步到磁盘的频率等等.</span><br><span class="line"></span><br><span class="line">9、EXPIRE：过期时间。为了提高内存使用率，对于很老的历史数据，可以通过设置过期时间使得超过阀值的行数据过期。但是过期参数只适合行表。</span><br><span class="line"></span><br><span class="line">10、COLUMN_BATCH_SIZE：刚才提到了，delta row buffer的batch大小，默认24MB。超过阀值就会写到列表。</span><br><span class="line"></span><br><span class="line">11、COLUMN_MAX_DELTA_ROWS：delta row buffer的最大行数，默认10000行。超过阀值会写到列表。</span><br></pre></td></tr></table></figure><p>除此之外，列表上也有些限制，例如不能设置主键、唯一约束、索引、不适合过期设置，LRUCount的驱逐不适合，<strong>READ_COMMITTED</strong>和<strong>REPEATABLE_READ</strong>的隔离级别不适合列表。</p><h3 id="API及其他组件"><a href="#API及其他组件" class="headerlink" title="API及其他组件"></a>API及其他组件</h3><p>SnappyData中支持2种API：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1、标准SQL+Spark SQL</span><br><span class="line">2、Spark API</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">我们可以把SnappyData当做一个SQL数据库，Spark SQL Catalyst会解析SQL，生成可执行的物理执行计划并代码生成Spark的job去执行。但是，并不是所有的SQL语句都交给Spark去解析。对于行表上快速的点update这种OLTP操作，会由P2P网络负责，同时直接追加到列表时尚的点insert操作，也会交给GemFire处理，这样做的目的不用通过Spark Job执行，加快执行速度。</span><br><span class="line"></span><br><span class="line">P2P(peer-to-peer)网络组件的作用有3个：</span><br></pre></td></tr></table></figure><p>1、发现服务：检测新成员的加入或member失败。<br>2、副本一致性：同步复制副本数据。<br>3、快速点更新<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">客户端可以通过JDBC或ODBC(企业版才支持)连接到SnappyData。除此之外，流处理功能则依赖Spark Streaming组件实现。</span><br><span class="line"></span><br><span class="line">SDE是Synopsis Data Engine的简称，核心要素是通过分层采样等方法对超大规模的历史数据建立采样表，通过允许丢失一定比例的准确性，达到快速返回结果的目的。这也是流处理概念的核心：在准确性和低延迟之间做的一种取舍。这种方法也叫AQP(approximate query processing)，即近似查询处理，但是只有企业版中才支持。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 数据流程</span><br><span class="line"></span><br><span class="line">![](ingestion.png)</span><br><span class="line"></span><br><span class="line">图中共有6个步骤，表明了数据从导入到查询的通常步骤：</span><br></pre></td></tr></table></figure></p><p>1、原始数据导入：一旦集群建立，就可以从外部数据源(HDFS、Hive、MySQL、Oracle、csv等)中导入历史数据；行存或列存根据需求而定。</p><p>2、流式数据实时注入：你可以将实时产生的数据插入到SnappyData，可以采用Spark Streaming的DStream将批量的数据导入，当然也可以采用其他框架(Flink等)来批量导入实时数据。</p><p>3、实时查询：当实时数据注入后，你便可以用SQL进行复杂的、多维度聚合的数据(实时+历史)。</p><p>4、delta row buffer：在数据被写入列表前，会先写到高速的row buffer中，且它具有合并的功能，在老化到(根据COLUMN_BATCH_SIZE和COLUMN_MAX_DELTA_ROWS)列表前，只会存储最终的状态。</p><p>5、防止OOM：表可以设置为持久化到磁盘和溢出到磁盘(LRU算法)，以防止OOM。而且，当历史数据过大或者不再查询时，可以将这些数据写到HDFS中。</p><p>6、ad-hoc查询：数据注入后，用户既可以对实时数据进行交互式的查询，也可以结合历史数据进行OLAP分析。用户也可以使用AQP功能，AQP功能会牺牲准确性从而达到低延迟的目的，但AQP只在企业版中支持。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### SnappyData角色</span><br><span class="line"></span><br><span class="line">![](architecture.png)</span><br><span class="line"></span><br><span class="line">SnappyData集群是有3种不同的角色组成的P2P网络：</span><br></pre></td></tr></table></figure></p><p>1、Locator：发现新成员的加入，接受客户端请求，失败恢复等。为了高可用，通常locator有2个，一主一备。</p><p>2、Lead Node：相当于Spark Driver的角色，负责集群管理并分发Spark Job给Executor；通常也是一主一备。</p><p>3、Data Servers：存储数据；同时扮演Executor的角色执行任务计算。Server角色负责对locator发送的请求进行SQL解析，如果数据只涉及本节点，那么无需发送给lead，直接在本地进行计算；否则发送给lead，由lead负责分发job到各个对应的节点进行计算。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">上图中我们可以看到，客户端通过JDBC或者ODBC，指定locator的地址进行连接；locator会将客户端的连接分发到不同的server；server负责解析SQL，并判断是否交给lead进行job部署,这里有些SQL语句是不需要由lead生成spark job的，例如show tables，行表上的操作，insert into XX values(xx)单点插入等；如果是复杂的SQL，则交给lead进行分发，具体的执行则分发到各个server执行计算。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 混合集群管理器</span><br><span class="line"></span><br><span class="line">![](hybrid_cluster.png)</span><br><span class="line"></span><br><span class="line">Spark主要是用于批处理操作，通常对大量数据的处理(包括多表join等)时间都比较高。但是这对于SnappyData来讲无法接受，好在SnappyData利用了全内存、与Spark存储格式一致、colocate多表等特点，得以将延迟降低到秒级或者毫秒级。</span><br><span class="line"></span><br><span class="line">除此之外，SnappyData还必须拥有满足额外的需求才可以作为一个实时的SQL数据库使用。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 高并发</span><br><span class="line"></span><br><span class="line">面对高并发，SnappyData将客户端所有的请求分成2类：</span><br></pre></td></tr></table></figure></p><p>1、低延迟的请求<br>2、高延迟的请求<br><code>`</code><br>对于低延迟的请求，SnappyData会跳过Spark的调度，而是直接由GemFireXD处理数据，例如上边提到的行表的操作，点插入，show或describe命令等；</p><p>而对于高延迟的请求，则会根据Spark的Fair调度机制分发到各个server执行计算，例如列表上的select或者点更新，批量DML等。</p><h4 id="状态共享"><a href="#状态共享" class="headerlink" title="状态共享"></a>状态共享</h4><p>SnappyData是一个Shared Nothing存储，完全的分布式本地存储。但是不同的job之间，数据是可以共享的。原因就是因为SnappyData本身也是个存储引擎，其数据完全驻留在内存中，因此天然具有状态共享的优点。</p><h4 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h4><p>发现服务：SnappyData是个P2P网络，因此它提供了发现服务，即提供一个包括lead和server的列表。</p><p>组协调器：最先加入的成员自然成为了coordinator角色，这个角色会不断的检测当前的member，并与初始的列表进行对比以确保所有成员是可用的。当有新的成员加入时，根据发现服务，coordinator会将新加入的成员加入列表并把一些数据同步到其节点中。</p><p>失败检测：对于节点失败是很容易检测到的；而对于网络分裂或者脑裂情况，就会比较复杂一些。SnappyData通过UDP neighbor ping等机制进行多次检测，以确定疑似的失败是否是真正的失败。</p><p>HA：SnappyData另一个高可用的地方表现在其Lead节点的HA，即可配置primary角色和standby角色。选举则根据分布式锁服务，先到的就是primary。</p><h4 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h4><p>SnappyData提供了<strong>read committed</strong>和<strong>repeatable read</strong>两种事务隔离级别。在写入发生时，会对所有的副本加排他锁，这里有个假设就是很少出现不能获得排他写锁的情况，提交的时候会应用到所有的副本。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>到此为止，关于SnappyData的架构，基本就讲完了。我们后续会继续根据SnappyData的使用写一个应用类的博客。</p><p>也欢迎大家加入<a href="http://47.104.162.24/" target="_blank" rel="noopener">SnappyData专业中文社区</a>和<strong>SnappyData中国用户组</strong>微信群进行交流。</p><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p><a href="https://www.snappydata.io/snappy-industrial" target="_blank" rel="noopener">SnappyData: Streaming, Transactions, and Interactive<br>Analytics in a Unified Engine</a></p><p><a href="https://snappydatainc.github.io/snappydata/architecture/core_components/" target="_blank" rel="noopener">官方文档</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;SnappyData既是个存储引擎，也是个计算引擎。这篇文章主要针对SnappyData的核心组件进行讲解。&lt;/p&gt;
&lt;h3 id=&quot;核心组件&quot;&gt;&lt;a href=&quot;#核心组件&quot; class=&quot;headerlink&quot; title=&quot;核心组件&quot;&gt;&lt;/a&gt;核心组件&lt;/h3&gt;&lt;p&gt;
      
    
    </summary>
    
      <category term="科普" scheme="http://yoursite.com/categories/%E7%A7%91%E6%99%AE/"/>
    
    
  </entry>
  
  <entry>
    <title>SnappyData与TiDB,Spark,Flink的对比-1</title>
    <link href="http://yoursite.com/2018/03/19/SnappyData%E4%B8%8ETiDB,Spark,Flink%E7%9A%84%E5%AF%B9%E6%AF%94-1/"/>
    <id>http://yoursite.com/2018/03/19/SnappyData与TiDB,Spark,Flink的对比-1/</id>
    <published>2018-03-19T08:55:31.000Z</published>
    <updated>2018-03-20T02:09:09.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="SnappyData是什么？"><a href="#SnappyData是什么？" class="headerlink" title="SnappyData是什么？"></a>SnappyData是什么？</h3><p><strong>SnappyData</strong>是一个开源的内存分布式存储与计算引擎，提供实时的、HTAP(OLTP+OLAP)场景的解决方案，融合了Apache Spark与GemFire数据库，以多种数据模型提供复杂的、实时的、多维度的OLAP分析，完全支持标准SQL与Spark SQL。</p><p>分析人员只需通过SQL便可对实时数据进行低延迟且高准确性的分析工作。</p><h3 id="SnappyData的特性"><a href="#SnappyData的特性" class="headerlink" title="SnappyData的特性"></a>SnappyData的特性</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1、分布式存储+计算引擎</span><br><span class="line">2、完全基于内存</span><br><span class="line">3、融合了Gemfire与Apache Spark的特性</span><br><span class="line">4、支持行存，且支持列存(压缩)</span><br><span class="line">5、对行存与列存都支持DML操作</span><br><span class="line">6、区分开源版本与闭源版本(支持off-heap与AQP功能)</span><br><span class="line">7、存储时可指定关联关系，使得数据本地化(colocate)，多表join性能是Spark的20倍+</span><br><span class="line">8、完全兼容Spark，支持标准SQL与Spark SQL</span><br><span class="line">9、对实时数据的处理只需用标准SQL或Spark SQL即可，同时由于其存储明细数据，使得对实时数据的处理既支持乱序又支持Retraction，非常适合ad-hoc类查询</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="与TiDB对比"><a href="#与TiDB对比" class="headerlink" title="与TiDB对比"></a>与TiDB对比</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TiDB是基于KV的行存；SnappyData支持列存。</span><br><span class="line">TiDB更适合OLTP事务；SnappyData更适合OLAP分析。</span><br><span class="line">TiDB存储于RocksDB；SnappyData完全内存，且支持overflow。</span><br><span class="line">TiDB支持DQL、DML与DDL；SnappyData也支持DQL、DML与DDL。</span><br><span class="line">TiDB支持分布式的多副本；SnappyData也支持多副本。</span><br><span class="line">TiSpark基于Spark处理复杂SQL；SnappyData存储采用与Spark一样的存储格式，省去加载的时间，同时支持colocate，使得join时性能提升2个级别</span><br></pre></td></tr></table></figure><h3 id="SnappyData相比于Spark的优势"><a href="#SnappyData相比于Spark的优势" class="headerlink" title="SnappyData相比于Spark的优势"></a>SnappyData相比于Spark的优势</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Spark的RDD不可变；SnappyData可变(Gemfire)，因此SnappyData的数据支持DML</span><br><span class="line">Spark需要从外部数据源加载数据；SnappyData不需要加载，存储格式与Spark的DataFrame一致</span><br><span class="line">Spark计算时基于内存；SnappyData计算转换为Spark Job，也是基于内存(不是所有的SQL都走Spark Job)</span><br><span class="line">Spark对于多表join，涉及跨机器join，性能受限；SnappyData存储支持表间colocate，join发生在机器本地，性能提高</span><br></pre></td></tr></table></figure><h3 id="SnappyData相比于Flink的优势"><a href="#SnappyData相比于Flink的优势" class="headerlink" title="SnappyData相比于Flink的优势"></a>SnappyData相比于Flink的优势</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Flink流处理的API是DataStream，学习成本较高；SnappyData API支持标准SQL与Spark SQL，学习成本较低。</span><br><span class="line">Flink的Stream SQL目前支持功能有限，尤其是流表join与双流join</span><br><span class="line">Flink在单流的汇总功能强大，双流join欠缺准确性；SnappyData支持多个表的join，且准确性极高</span><br><span class="line">Flink的处理延时极低(毫秒级)；SnappyData处理延迟同样极低(毫秒级)</span><br><span class="line">Flink处理一个需求就需要单独一个job；SnappyData简单很多，一个SQL对应一个需求，效率极高</span><br><span class="line">Flink支持乱序及Retraction，但是已经发出的结果不能更改；SnappyData由于存储明细数据，因此也支持乱序与Retraction，同时对于已经发出的结果，同样可以更改(客户端只需再次调用一遍SQL即可)</span><br><span class="line">Flink实时处理不能很好的关联大量的历史数据；SnappyData随意关联历史数据，通过SQL不但可以查询实时数据，同样可查询历史数据</span><br></pre></td></tr></table></figure><h3 id="SnappyData的劣势"><a href="#SnappyData的劣势" class="headerlink" title="SnappyData的劣势"></a>SnappyData的劣势</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、尽管列存支持压缩，从而大幅度减少数据量，同时可以横向扩展，但是内存空间的使用仍然使得成本较高</span><br><span class="line">2、存储+计算都在内存进行，且Spark Job的运行基于JVM，要注意防止内存不足的情况出现</span><br><span class="line">3、社区不够活跃</span><br><span class="line">4、对于PB及以上的数据规模，即使横向扩展也不太适合这种规模</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;SnappyData是什么？&quot;&gt;&lt;a href=&quot;#SnappyData是什么？&quot; class=&quot;headerlink&quot; title=&quot;SnappyData是什么？&quot;&gt;&lt;/a&gt;SnappyData是什么？&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;SnappyData&lt;/strong&gt;是一个开源的内存分布式存储与计算引擎，提供实时的、HTAP(OLTP+OLAP)场景的解决方案，融合了Apache Spark与GemFire数据库，以多种数据模型提供复杂的、实时的、多维度的OLAP分析，完全支持标准SQL与Spark SQL。&lt;/p&gt;
&lt;p&gt;分析人员只需通过SQL便可对实时数据进行低延迟且高准确性的分析工作。&lt;/p&gt;
&lt;h3 id=&quot;SnappyData的特性&quot;&gt;&lt;a href=&quot;#SnappyData的特性&quot; class=&quot;headerlink&quot; title=&quot;SnappyData的特性&quot;&gt;&lt;/a&gt;SnappyData的特性&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1、分布式存储+计算引擎&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2、完全基于内存&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3、融合了Gemfire与Apache Spark的特性&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4、支持行存，且支持列存(压缩)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5、对行存与列存都支持DML操作&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6、区分开源版本与闭源版本(支持off-heap与AQP功能)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7、存储时可指定关联关系，使得数据本地化(colocate)，多表join性能是Spark的20倍+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8、完全兼容Spark，支持标准SQL与Spark SQL&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9、对实时数据的处理只需用标准SQL或Spark SQL即可，同时由于其存储明细数据，使得对实时数据的处理既支持乱序又支持Retraction，非常适合ad-hoc类查询&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="对比" scheme="http://yoursite.com/categories/%E5%AF%B9%E6%AF%94/"/>
    
    
  </entry>
  
  <entry>
    <title>欢迎来到SnappyData中文博客</title>
    <link href="http://yoursite.com/2018/03/19/%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E4%B8%AD%E6%96%87%E5%8D%9A%E5%AE%A2/"/>
    <id>http://yoursite.com/2018/03/19/欢迎来到中文博客/</id>
    <published>2018-03-19T04:12:57.000Z</published>
    <updated>2018-03-20T02:06:12.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="关于SnappyData"><a href="#关于SnappyData" class="headerlink" title="关于SnappyData"></a>关于SnappyData</h3><p><strong>SnappyData</strong>是一个<strong>开源的</strong>、<strong>内存分布式**</strong>存储<strong>与</strong>计算引擎<strong>，提供</strong>实时的<strong>、</strong>HTAP(OLTP+OLAP)**场景的解决方案。</p><p>它融合了<strong>Apache Spark</strong>与<strong>GemFire</strong>数据库，以多种数据模型(行表+列表)提供复杂的、实时的、多维度的OLAP分析与OLTP事务处理，完全支持<strong>标准SQL</strong>与<strong>Spark SQL</strong>。</p><p>分析人员只需通过SQL便可对实时数据进行<strong>低延迟</strong>与<strong>高准确性</strong>(对<strong>乱序的处理与Retraction的支持</strong>)的分析工作。</p><a id="more"></a><h3 id="SnappyData中文社区"><a href="#SnappyData中文社区" class="headerlink" title="SnappyData中文社区"></a>SnappyData中文社区</h3><p><a href="http://47.104.162.24/" target="_blank" rel="noopener">SnappyData专业中文社区</a></p><h3 id="博客支持"><a href="#博客支持" class="headerlink" title="博客支持"></a>博客支持</h3><p>该中文博客由<code>美团旅行-住宿事业部-经营效率组</code>维护，并不定期发布<strong>SnappyData</strong>相关博客。</p><h3 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h3><p><a href="https://www.snappydata.io/community" target="_blank" rel="noopener">SnappyData官方社区</a></p><p><a href="https://www.snappydata.io/blog" target="_blank" rel="noopener">SnappyData官方博客</a></p><p><a href="https://snappydatainc.github.io/snappydata/" target="_blank" rel="noopener">SnappyData官方文档</a></p><p><a href="https://www.snappydata.io/" target="_blank" rel="noopener">SnappyData官方网站</a></p><p><a href="http://47.104.162.24/" target="_blank" rel="noopener">SnappyData专业中文社区</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;关于SnappyData&quot;&gt;&lt;a href=&quot;#关于SnappyData&quot; class=&quot;headerlink&quot; title=&quot;关于SnappyData&quot;&gt;&lt;/a&gt;关于SnappyData&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;SnappyData&lt;/strong&gt;是一个&lt;strong&gt;开源的&lt;/strong&gt;、&lt;strong&gt;内存分布式**&lt;/strong&gt;存储&lt;strong&gt;与&lt;/strong&gt;计算引擎&lt;strong&gt;，提供&lt;/strong&gt;实时的&lt;strong&gt;、&lt;/strong&gt;HTAP(OLTP+OLAP)**场景的解决方案。&lt;/p&gt;
&lt;p&gt;它融合了&lt;strong&gt;Apache Spark&lt;/strong&gt;与&lt;strong&gt;GemFire&lt;/strong&gt;数据库，以多种数据模型(行表+列表)提供复杂的、实时的、多维度的OLAP分析与OLTP事务处理，完全支持&lt;strong&gt;标准SQL&lt;/strong&gt;与&lt;strong&gt;Spark SQL&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;分析人员只需通过SQL便可对实时数据进行&lt;strong&gt;低延迟&lt;/strong&gt;与&lt;strong&gt;高准确性&lt;/strong&gt;(对&lt;strong&gt;乱序的处理与Retraction的支持&lt;/strong&gt;)的分析工作。&lt;/p&gt;
    
    </summary>
    
      <category term="科普" scheme="http://yoursite.com/categories/%E7%A7%91%E6%99%AE/"/>
    
    
  </entry>
  
</feed>
